---
title: "DHARMa - Residual Diagnostics for HierArchical (Multi-level / Mixed) Regression Models"
author: "Florian Hartig"
output: 
  rmarkdown::html_vignette:
    toc: true
vignette: >
  %\VignetteIndexEntry{Vignette for the DHARMa package}
  %\VignetteEngine{knitr::rmarkdown}
  \usepackage[utf8](inputenc)
---

```{r, echo = F}
library(DHARMa)
set.seed(123)
```


```{r global_options, include=FALSE}
knitr::opts_chunk$set(fig.width=8, fig.height=5, warning=FALSE, message=FALSE, cache = F)
```

***Summary**: Diagnosing ge


The DHARMa package creates readily interpretable residuals for generalized linear (mixed) models that are standardized to values between 0 and 1. This is achieved by a simulation-based approach, similar to the Bayesian p-value or the parametric bootstrap: 1) simulate new data from the fitted model 2) from this simulated data, calculate the cummulative density function  3) residual is the value of the empirical density function at the value of the observed data.*  

# Motivation 

Residual interpretation for generalized linear mixed models is often problematic. As an example, here two Poisson models, one with serious overdispersion, and one that fits the data perfectly. I show three standard residuals diagnostics each. Can you say which is the overdispersed model?


```{r, echo = F}
library(lme4)

overdispersedData = createData(sampleSize = 250, overdispersion = 2, family = poisson())
fittedModelOverdispersed <- glmer(observedResponse ~ Environment1 + (1|group) , family = "poisson", data = overdispersedData)

plotConventionalResiduals(fittedModelOverdispersed)


testData = createData(sampleSize = 250, intercept = 0, overdispersion = 0, family = poisson(), randomEffectVariance = 0)
fittedModel <- glmer(observedResponse ~ Environment1 + (1|group) , family = "poisson", data = testData)

plotConventionalResiduals(fittedModel)

```

Just for completeness - the first model is the overdispersed model. Don't get too excited if you got it right. Likely, you were simply lucky. Misspecifications in GL(M)Ms cannot reliably be diagnosed with standard residual plots. 

The reason is that in GL(M)Ms distribution shapes change with fitted values in all kind of ways. Simple reweightings as done in the Pearson residuals does not lead to visually homogenous residuals. Also deviance residuals don't solve that problem, because likelihood densities are equally non-homogenous, even in correctly specified models. As a result, standard residual plots, when interpreted in the same way as for linear models, seem to show all kind problems such as non-normality, heteroskedasticity and so on, even if the model is correctly specified, which regularly confuses statistical beginners. 

The more serious problem, however, is that even experienced statistical analysis have currently few options to diagnose problems in the specification of GLMMs. I would hold that the current standard practice is to eyeball residual plots for major misspecifications, and the run a test for overdispersion, which asks if the overall variation in the observations is larger or smaller than expected under the fitted model. This approach, however, has a number of problems. For example, heteroskedasticity cannot be reliably be diagnosed. 

A more reliable model 


# Workflow in DHARMa

## Installing, loading and citing the package

If you haven't installed the package yet, run

```{r, eval = F}
library(devtools)
install_url("https://dl.dropboxusercontent.com/s/xlvjf0vpslukl29/DHARMa.tar.gz", dependencies = T)
```

loading and citation

```{r}
set.seed(1)
library(DHARMa)
citation("DHARMa")
```

## Calculating and plotting scaled residuals 

The scaled residuals are calculated with the simulateResiduals() functions. You have to specify the number of simulations. The default number of simulations to run is 250, but for very stable results you may want to increase this number. 

```{r}
simulationOutput <- simulateResiduals(fittedModel = fittedModel, n = 250, refit = F, integerResponse = NULL)
```

You can plot the residuals with the plotSimulatedResiduals() function

```{r}
plotSimulatedResiduals(simulationOutput = simulationOutput)
```



## Hypothesis tests in DHARMa

You can run a hypothesis test on the residuals, which runs a KS test on the uniformity of the simulated residuals

```{r}
testSimulatedResiduals(simulationOutput = simulationOutput)
```

Note, however, that simulations show that this test is less powerfull than parametric tests on the likelihood that are currently run by many people. On the other hand, the parametric tests


```{r}
dispersionTest(fittedModel, type = 1)
```



## Interpretation of the residual plots

The above exampel shows a misspecified model. The reason is that we created data with overdispersion, but the fitted model does not include overdispersion. For a correctly specified model, one would expect

* a flat histogram of the scaled residuals
* no pattern against the fitted value

### Perfect residuals

As a comparison to the examle above, we show below the residual plots of a correctly specified model 

```{r}
simulationOutput <- simulateResiduals(fittedModel = fittedModel)
plotSimulatedResiduals(simulationOutput = simulationOutput)
```


### Overdispersion / underdispersion / zero-inflation

Over/underdispersion refers to the phenomenon that that residual variance is larger/smaller than expected under the fitted model. Over/underdispersion can appear for any distributional family with fixed variance, in particular for Poisson and binomial models. 

A common special case of overdispersion is zero-inflation, which is the situation when more zeros appear in the observation than expected under the fitted model. Zero-inflation requires special correction steps. 

A few general rules of thumb

* You can detect overdispersion / zero-inflation only AFTER fitting the model
* Overdispersion is more common than underdispersion
* If overdispersion is present, confidence intervals tend to be too narrow, and p-values to small. The opposite is true for underdispersion
* A common reason for overdispersion is a misspecified models. When overdispersion is detected, one should therefore firest search for problems in the model specification (e.g. by plotting residuals against predictors), and only if this doesn't lead to success, overdispersion corrections such as individual-level random effects or changes in the distribution should be applied

#### An example of overdispersion

This this is how **overdispersion** looks like in the DHARMa residuals

```{r}
testData = createData(sampleSize = 500, overdispersion = 2, family = poisson())
fittedModel <- glmer(observedResponse ~ Environment1 + (1|group) , family = "poisson", data = testData)

simulationOutput <- simulateResiduals(fittedModel = fittedModel)
plotSimulatedResiduals(simulationOutput = simulationOutput)
```

#### An example of underdispersion

And this is underdispersion 

```{r}
testData = createData(sampleSize = 500, intercept=0, fixedEffects = 2, overdispersion = 0, family = poisson(), roundPoissonVariance = 0.001, randomEffectVariance = 0)
fittedModel <- glmer(observedResponse ~ Environment1 + (1|group) , family = "poisson", data = testData)

summary(fittedModel)

# plotConventionalResiduals(fittedModel)

simulationOutput <- simulateResiduals(fittedModel = fittedModel)
plotSimulatedResiduals(simulationOutput = simulationOutput)
testSimulatedResiduals(simulationOutput = simulationOutput)
```

#### An example of zero-inflation

```{r}

testData = createData(sampleSize = 500, intercept = 2, fixedEffects = c(1), overdispersion = 0, family = poisson(), quadraticFixedEffects = c(-3), randomEffectVariance = 0, pZeroInflation = 0.6)

par(mfrow = c(1,2))
plot(testData$Environment1, testData$observedResponse, xlab = "Envrionmental Predictor", ylab = "Response")
hist(testData$observedResponse, xlab = "Response", main = "")

fittedModel <- glmer(observedResponse ~ Environment1 + I(Environment1^2) + (1|group) , family = "poisson", data = testData)

simulationOutput <- simulateResiduals(fittedModel = fittedModel)
plotSimulatedResiduals(simulationOutput = simulationOutput)
```

There is a special function to visualize / test zero-inflation

```{r}
testZeroInflation(simulationOutput)
```



### Heteroscedasticity


Also binomial or poisson models can show heteroscedasticity, meaning that the dispersion parameter changes with some other parameter. Here an example where we create such data 

```{r}
testData = createData(sampleSize = 500, intercept = 0, overdispersion = function(x){return(rnorm(length(x), sd = 2*abs(x)))}, family = poisson(), randomEffectVariance = 0)
fittedModel <- glmer(observedResponse ~ Environment1 + (1|group), family = "poisson", data = testData)

simulationOutput <- simulateResiduals(fittedModel = fittedModel)
plotSimulatedResiduals(simulationOutput = simulationOutput)
testSimulatedResiduals(simulationOutput = simulationOutput)
```

Adding a simple overdispersion correct will not completely remove the problem. The qq plot looks better, but there is still a pattern in the residuals 

```{r}
testData = createData(sampleSize = 500, intercept = 0, overdispersion = function(x){return(rnorm(length(x), sd = 2*abs(x)))}, family = poisson(), randomEffectVariance = 0)
fittedModel <- glmer(observedResponse ~ Environment1 + (1|group) + (1|ID), family = "poisson", data = testData)

# plotConventionalResiduals(fittedModel)

simulationOutput <- simulateResiduals(fittedModel = fittedModel)
plotSimulatedResiduals(simulationOutput = simulationOutput)
testSimulatedResiduals(simulationOutput = simulationOutput)
```

## Diagnosing more complicated model misspecification such as missing predictors or quadratic effects 

You don't have to rely on the overall qq and residual against predicted plots that are provided. To diagnose model misspecification (e.g. missing predictor), or spatial or temporal autorcorrelation it is *highly recommeded* to plot residuals against (where possible)

* all predictors
* space
* time

For that purpose, you can retrieve the residuals via 

```{r, eval = F}
simulationOutput$scaledResiduals
```

Note again that the residual values are scaled between 0 and 1. If you plot the residuals against predictors, space or time, the resulting plots should not only show no systematic dependency of those residuals on the covariates, but they should also again be flat for each fixed situation. That means that if you have, for example, a categorical predictor: treatment / control, the distribution of residuals for each predictor alone should be flat as well. 

Here an example with a missing quadratic effect in the model and 2 predictors

```{r}
testData = createData(sampleSize = 200, intercept = 1, fixedEffects = c(1,2), overdispersion = 0, family = poisson(), quadraticFixedEffects = c(-3,0))
fittedModel <- glmer(observedResponse ~ Environment1 + Environment2 + (1|group) , family = "poisson", data = testData)
simulationOutput <- simulateResiduals(fittedModel = fittedModel)
# plotConventionalResiduals(fittedModel)
plotSimulatedResiduals(simulationOutput = simulationOutput, quantreg = T)
testSimulatedResiduals(simulationOutput = simulationOutput)
```

Difficult to see with the overall pattern, but it becomes clear if we plot against the environment

```{r}
par(mfrow = c(1,2))
plotResiduals(testData$Environment1,  simulationOutput$scaledResiduals)
plotResiduals(testData$Environment2,  simulationOutput$scaledResiduals)
```




# Further examples


## Binomial GLMM

works exactly as before

```{r}
testData = createData(sampleSize = 500, overdispersion = 2, family = binomial())
fittedModel <- glmer(observedResponse ~ Environment1 + (1|group) , family = "binomial", data = testData)
summary(fittedModel)
# plotConventionalResiduals(fittedModel)

simulationOutput <- simulateResiduals(fittedModel = fittedModel)
plotSimulatedResiduals(simulationOutput = simulationOutput)
testSimulatedResiduals(simulationOutput = simulationOutput)
```

## Binomial GLM

```{r}
fittedModel <- glm(observedResponse ~ Environment1 , family = "binomial", data = testData)
summary(fittedModel)
# plotConventionalResiduals(fittedModel)

simulationOutput <- simulateResiduals(fittedModel = fittedModel)
plotSimulatedResiduals(simulationOutput = simulationOutput)
testSimulatedResiduals(simulationOutput = simulationOutput)
```

## LM on binomial data - just to show that this also works

```{r}
fittedModel <- lm(observedResponse ~ Environment1 , data = testData)
summary(fittedModel)
# plotConventionalResiduals(fittedModel)

simulationOutput <- simulateResiduals(fittedModel = fittedModel)
plotSimulatedResiduals(simulationOutput = simulationOutput)
testSimulatedResiduals(simulationOutput = simulationOutput)
```

## LMM on binomial data - just to show that this also works

```{r}
fittedModel <- lmer(observedResponse ~ Environment1 + (1|group) , data = testData)
summary(fittedModel)
# plotConventionalResiduals(fittedModel)

simulationOutput <- simulateResiduals(fittedModel = fittedModel)
plotSimulatedResiduals(simulationOutput = simulationOutput)
testSimulatedResiduals(simulationOutput = simulationOutput)
```


# Real examples

## Budworm example

Example from Jochen Fründ, 

```{r, echo = F}
data = structure(list(N_parasitized = c(226, 689, 481, 960, 1177, 266, 
46, 4, 884, 310, 19, 4, 7, 1, 3, 0, 365, 388, 369, 829, 532, 
5), N_adult = c(1415, 2227, 2854, 3699, 2094, 376, 8, 1, 1379, 
323, 2, 2, 11, 2, 0, 1, 1394, 1392, 1138, 719, 685, 3), density.attack = c(216.461273226486, 
214.662143448767, 251.881252132684, 400.993643475831, 207.897856251888, 
57.0335141562012, 6.1642552100285, 0.503930659141302, 124.673812637575, 
27.3764667492035, 0.923453215863429, 0.399890030241684, 0.829818131526174, 
0.146640466903247, 0.216795117773948, 0.215498663908284, 110.635445098884, 
91.3766566822467, 126.157080458047, 82.9699108890686, 61.0476207779938, 
0.574539291305784), Plot = structure(c(1L, 1L, 1L, 1L, 1L, 1L, 
1L, 1L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 3L, 3L, 3L, 3L, 3L, 3L
), .Label = c("1", "2", "3", "4"), class = "factor"), PY = c("p1y82", 
"p1y83", "p1y84", "p1y85", "p1y86", "p1y87", "p1y88", "p1y89", 
"p2y86", "p2y87", "p2y88", "p2y89", "p2y90", "p2y91", "p2y92", 
"p2y93", "p3y88", "p3y89", "p3y90", "p3y91", "p3y92", "p3y93"
), Year = c(82, 83, 84, 85, 86, 87, 88, 89, 86, 87, 88, 89, 90, 
91, 92, 93, 88, 89, 90, 91, 92, 93), ID = 1:22), .Names = c("N_parasitized", 
"N_adult", "density.attack", "Plot", "PY", "Year", "ID"), row.names = c("p1y82", 
"p1y83", "p1y84", "p1y85", "p1y86", "p1y87", "p1y88", "p1y89", 
"p2y86", "p2y87", "p2y88", "p2y89", "p2y90", "p2y91", "p2y92", 
"p2y93", "p3y88", "p3y89", "p3y90", "p3y91", "p3y92", "p3y93"
), class = "data.frame")
```

Fitting the model with a regular Poisson model

```{r}
mod1 <- glm(cbind(N_parasitized, N_adult) ~ log10(density.attack+1), data = data, family=binomial)
simulationOutput <- simulateResiduals(fittedModel = mod1)
plotSimulatedResiduals(simulationOutput = simulationOutput)
```

The residuals look clearly overdispersed. We can confirm that with a 

```{r}
testSimulatedResiduals(simulationOutput = simulationOutput)
```



```{r}
mod2 <- glmer(cbind(N_parasitized, N_adult) ~ log10(density.attack+1) + (1|ID), data = data, family=binomial)
simulationOutput <- simulateResiduals(fittedModel = mod2)
plotSimulatedResiduals(simulationOutput = simulationOutput)

```

Overdispersion looks better, but seems like a quadratic effect is missing

```{r}
mod3 <- glmer(cbind(N_parasitized, N_adult) ~ log10(density.attack+1) + I(log10(density.attack+1)^2) + (1|ID) + (1|Plot), data = data, family=binomial)
simulationOutput <- simulateResiduals(fittedModel = mod3)
plotSimulatedResiduals(simulationOutput = simulationOutput)
```

Final model 

```{r}
summary(mod3)
```



